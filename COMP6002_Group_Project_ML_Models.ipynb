{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "60pYh9NWQbIB",
        "O4bSSnwGQfiL"
      ],
      "authorship_tag": "ABX9TyMFYyeu7V0HOL9CVAtXLFcP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frosk-Kristian/COMP6002-Group10-Models/blob/develop/COMP6002_Group_Project_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMP6002 Computer Science Project - Group 10\n",
        "Utilising Machine Learning to detect DDoS attacks."
      ],
      "metadata": {
        "id": "vkidwNbBPly0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "zN1_GsQjkwEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wgQiJbJiPMYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cd1e3f-72ec-40c3-b359-a6a0687c9b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Pandas version: 1.5.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(\"Using Pandas version: {}\".format(pd.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask\n",
        "\n",
        "import dask\n",
        "print(\"Using Dask version: {}\".format(dask.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxddjYl-k_DT",
        "outputId": "8773e764-acaa-4b51-cc6b-001a9ceec9b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.18.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask) (1.0.0)\n",
            "Using Dask version: 2023.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask-ml\n",
        "\n",
        "import dask_ml\n",
        "print(\"Using Dask-ML version: {}\".format(dask_ml.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF5M0nW8oVCK",
        "outputId": "925183ac-7467-432d-f691-3a19ea67bcb8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask-ml in /usr/local/lib/python3.10/dist-packages (2024.3.20)\n",
            "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (2023.8.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.11.4)\n",
            "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (0.3.2)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dask-ml) (24.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask-ml) (2.2.1)\n",
            "Requirement already satisfied: sparse>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask-ml) (0.15.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (7.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.1.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.0.7)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask-ml) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask-ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask-ml) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask-ml) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask-ml) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->dask-ml) (1.16.0)\n",
            "Using Dask-ML version: 2024.3.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import __version__ as skl_ver\n",
        "print(\"Using Sklearn version: {}\".format(skl_ver))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg4eRaq0fNry",
        "outputId": "796126c4-ea4d-4c3e-d5f1-ca5790703c78"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Sklearn version: 1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import & Export Trained Models"
      ],
      "metadata": {
        "id": "eEz2Qzc_kzkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions for exporting/importing models trained with Sklearn, do not attempt to use with Neural Network as the library used has its' own methods for exporting/importing\n",
        "# all functions defined will prompt the user for confirmation, to allow for skipping the functions when running the notebook\n",
        "import joblib\n",
        "print(\"Using Joblib version: {}\".format(joblib.__version__))\n",
        "\n",
        "# Save a trained model to the provided filepath\n",
        "def SaveSKL(model, model_fpath):\n",
        "  \"\"\"\n",
        "  Exports a trained model via joblib.\n",
        "\n",
        "  Parameters:\n",
        "    model (object): model to be saved.\n",
        "    model_fpath (string): file path that the model will be saved in.\n",
        "  Returns:\n",
        "    : no value returned.\n",
        "  \"\"\"\n",
        "  to_save = \"\"\n",
        "  while to_save.lower() not in ('y', 'n'):\n",
        "    to_save = input(\"Do you wish to save the trained model? (y/n)\\n\")\n",
        "    if to_save.lower() in 'y':\n",
        "      print(\"Saving model to: {}\".format(model_fpath))\n",
        "      try:\n",
        "        joblib.dump(model, model_fpath)\n",
        "        print(\"SUCCESS: Model saved to {}\".format(model_fpath))\n",
        "      except:\n",
        "        print(\"ERROR: An unknown error has occured when calling joblib.dump()!\")\n",
        "    else:\n",
        "      if to_save.lower() in 'n':\n",
        "        print(\"Did not save model.\")\n",
        "      else:\n",
        "        print(\"Please only enter \\'y\\' to save model or \\'n\\' to skip saving.\")\n",
        "\n",
        "# Load a trained model from the provided filepath\n",
        "def LoadSKL(model_fpath):\n",
        "  \"\"\"\n",
        "  Import a trained model via joblib.\n",
        "\n",
        "  Parameters:\n",
        "    model_fpath (string): file path to the stored model.\n",
        "  Returns:\n",
        "    object: if a model is found and loaded correctly, returns an object.\n",
        "    None: if no matching file is found or an error occurs during loading, returns None.\n",
        "  \"\"\"\n",
        "  to_load = \"\"\n",
        "  while to_load.lower() not in ('y', 'n'):\n",
        "    to_load = input(\"Do you wish to import a trained model? {y/n)\\n\")\n",
        "    if to_load.lower() in 'y':\n",
        "      model = None\n",
        "      print(\"Attempting to import model from: {}\".format(model_fpath))\n",
        "      try:\n",
        "        model = joblib.load(model_fpath)\n",
        "        print(\"SUCCESS: Model successfully imported.\")\n",
        "      except FileNotFoundError:\n",
        "        print(\"ERROR: The file \\'{}\\' does not exist!\".format(model_fpath))\n",
        "        model = None\n",
        "      except:\n",
        "        print(\"ERROR: An unknown error has occured when calling joblib.load()!\")\n",
        "        model = None\n",
        "      finally:\n",
        "        return model\n",
        "    else:\n",
        "      if to_load.lower() in 'n':\n",
        "        print(\"Did not import model.\")\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Please only enter \\'y\\' to import model or \\'n\\' to skip importing.\")\n",
        "\n",
        "# To-do: write function that exports model parameters, evaluation metrics, etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otJrdxCQXWv5",
        "outputId": "344c184d-c6ec-4bb9-9ad4-edc418e9a12f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Joblib version: 1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data\n",
        "Checks current working directory for datasets, if datasets are missing downloads a [.zip archive mirror of the CiCDDoS2019 hosted on Kaggle](https://www.kaggle.com/datasets/kristianfrossos/cicddos2019/data).\n",
        "\n",
        "**NOTE:** the first part of this section is specific to Google Colab, and will not work outside of it. Advise writing an alternative later for local use (relevant when training Neural Network for speed and when usage limits get in the way).\n",
        "\n",
        "## Reference\n",
        "Iman Sharafaldin, Arash Habibi Lashkari, Saqib Hakak, and Ali A. Ghorbani, \"Developing Realistic Distributed Denial of Service (DDoS) Attack Dataset and Taxonomy\", IEEE 53rd International Carnahan Conference on Security Technology, Chennai, India, 2019.\n"
      ],
      "metadata": {
        "id": "gSVADpSUPvxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "id": "rVY0RkBfOV1C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets up dataset directory\n",
        "import os"
      ],
      "metadata": {
        "id": "YRTgsphl2JqO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mounts google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# directory that the dataset will be downloaded to\n",
        "dl_dir = os.getcwd() + r'/drive/MyDrive/Colab Notebooks/COMP6002_Group10_Data'\n",
        "\n",
        "if os.path.exists(dl_dir):\n",
        "  print(\"Directory {} already exists.\\n\".format(dl_dir))\n",
        "else:\n",
        "  os.mkdir(dl_dir)\n",
        "  print(\"Successfully created the directory {}\".format(dl_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUdWg_050_Ro",
        "outputId": "0f60099b-ce8e-47c2-8fde-c5c38b2f0332"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory /content/drive/MyDrive/Colab Notebooks/COMP6002_Group10_Data already exists.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets up kaggle environment variables (needed to access API)\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "\n",
        "# checks if kaggle key and username have been provided as secrets and sets environment variables appropriately\n",
        "# if not found, attempts to use kaggle.json\n",
        "try:\n",
        "  os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "  os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "  print(\"Using KAGGLE_KEY and KAGGLE_USERNAME defined in secrets.\")\n",
        "except (userdata.SecretNotFoundError, userdata.NotebookAccessError):\n",
        "  print(\"WARN: One or more secret(s) missing or inaccessible.\\n\")\n",
        "  if os.path.isfile('~/.kaggle/kaggle.json'):\n",
        "    print(\"Using existing kaggle.json\")\n",
        "  else:\n",
        "    print(\"Please upload kaggle.json\")\n",
        "    files.upload()\n",
        "\n",
        "    if os.path.isfile(os.getcwd() + '/content/kaggle.json'):\n",
        "      !rm -r ~/.kaggle\n",
        "      !mkdir ~/.kaggle\n",
        "      !mv ./kaggle.json ~/.kaggle/\n",
        "      !chmod 600 ~/.kaggle/kaggle.json\n",
        "    else:\n",
        "      print(\"\\'kaggle.json\\' not uploaded.\")\n",
        "      raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcOT1v4TO4rm",
        "outputId": "35118d7a-fedb-479b-e3d3-9f3d4e717307"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using KAGGLE_KEY and KAGGLE_USERNAME defined in secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.getcwd() + '/dataset'\n",
        "\n",
        "# checks if .zip archive containing dataset already exists in google drive and downloads it if necessary\n",
        "if os.path.isfile(dl_dir + '/cicddos2019.zip'):\n",
        "  print(\"Dataset already present.\")\n",
        "else:\n",
        "  print(\"Downloading zipped dataset to {}\".format(dl_dir))\n",
        "  !kaggle datasets download kristianfrossos/cicddos2019 -p {dl_dir.replace(' ', '\\ ')}\n",
        "\n",
        "# creates the content/dataset directory if it doesn't already exist\n",
        "if os.path.exists(data_dir):\n",
        "  print(\"Directory {} already exists.\\n\".format(data_dir))\n",
        "else:\n",
        "  print(\"Created directory: {}\\n\".format(data_dir))\n",
        "  os.mkdir(data_dir)\n",
        "\n",
        "# extracts contents of .zip archive to content/dataset if directory is not empty\n",
        "if not os.listdir(data_dir):\n",
        "  print(\"Empty directory, extracting dataset.\")\n",
        "  # unzips .zip archive\n",
        "  !unzip {dl_dir.replace(' ', '\\ ') + '/cicddos2019.zip'} -d {data_dir}\n",
        "else:\n",
        "  print(\"Non-empty directory, skipping download\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUQvxpnNMnRQ",
        "outputId": "f925b7f9-7905-4770-bd32-93ec6c7f5969"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already present.\n",
            "Directory /content/dataset already exists.\n",
            "\n",
            "Non-empty directory, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialises empty list\n",
        "csv_list = []\n",
        "\n",
        "# iterates through all subdirectories of /content/dataset and appends the filepath of each .csv to csv_list\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "  for f in files:\n",
        "    if f.endswith(\".csv\"):\n",
        "      csv_list.append(os.path.join(root, f))\n",
        "\n",
        "# if .csv files were found, displays number of files and prints each path\n",
        "if not csv_list:\n",
        "  print(\"No .csv files found!\")\n",
        "else:\n",
        "  print(\"{} .csv files found.\".format(len(csv_list)))\n",
        "  for csv in csv_list:\n",
        "    print(csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMw9ryJSbiPL",
        "outputId": "e9a326cc-6d1f-493e-defe-7f9bec0f9221"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 .csv files found.\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_SSDP.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_SNMP.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_NTP.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_DNS.csv\n",
            "/content/dataset/CSV-01-12/01-12/Syn.csv\n",
            "/content/dataset/CSV-01-12/01-12/TFTP.csv\n",
            "/content/dataset/CSV-01-12/01-12/UDPLag.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_NetBIOS.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_LDAP.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_MSSQL.csv\n",
            "/content/dataset/CSV-01-12/01-12/DrDoS_UDP.csv\n",
            "/content/dataset/CSV-03-11/03-11/UDP.csv\n",
            "/content/dataset/CSV-03-11/03-11/NetBIOS.csv\n",
            "/content/dataset/CSV-03-11/03-11/Syn.csv\n",
            "/content/dataset/CSV-03-11/03-11/UDPLag.csv\n",
            "/content/dataset/CSV-03-11/03-11/MSSQL.csv\n",
            "/content/dataset/CSV-03-11/03-11/LDAP.csv\n",
            "/content/dataset/CSV-03-11/03-11/Portmap.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dask import dataframe as df\n",
        "\n",
        "dask_df = df.read_csv(csv_list)"
      ],
      "metadata": {
        "id": "cAAImz65is08"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default behaviour of describe, describes all numeric columns\n",
        "dask_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "oC0OrD0QnCKq",
        "outputId": "89fcf444-503a-457e-f58e-a0c18898c752"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask DataFrame Structure:\n",
              "              Unnamed: 0  Source Port  Destination Port  Protocol  Flow Duration  Total Fwd Packets  Total Backward Packets Total Length of Fwd Packets  Total Length of Bwd Packets  Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std Bwd Packet Length Max  Bwd Packet Length Min  Bwd Packet Length Mean  Bwd Packet Length Std Flow Bytes/s  Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Max  Flow IAT Min Fwd IAT Total  Fwd IAT Mean  Fwd IAT Std  Fwd IAT Max  Fwd IAT Min Bwd IAT Total  Bwd IAT Mean  Bwd IAT Std  Bwd IAT Max  Bwd IAT Min Fwd PSH Flags  Bwd PSH Flags  Fwd URG Flags  Bwd URG Flags  Fwd Header Length  Bwd Header Length Fwd Packets/s  Bwd Packets/s  Min Packet Length  Max Packet Length  Packet Length Mean  Packet Length Std  Packet Length Variance FIN Flag Count  SYN Flag Count  RST Flag Count  PSH Flag Count  ACK Flag Count  URG Flag Count  CWE Flag Count  ECE Flag Count  Down/Up Ratio  Average Packet Size  Avg Fwd Segment Size  Avg Bwd Segment Size  Fwd Header Length.1 Fwd Avg Bytes/Bulk  Fwd Avg Packets/Bulk  Fwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  Bwd Avg Packets/Bulk Bwd Avg Bulk Rate Subflow Fwd Packets  Subflow Fwd Bytes  Subflow Bwd Packets  Subflow Bwd Bytes Init_Win_bytes_forward  Init_Win_bytes_backward  act_data_pkt_fwd  min_seg_size_forward Active Mean  Active Std  Active Max  Active Min Idle Mean  Idle Std  Idle Max  Idle Min SimillarHTTP  Inbound\n",
              "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
              "                 float64      float64           float64   float64        float64            float64                 float64                     float64                      float64                float64                float64                 float64                float64               float64                float64                 float64                float64      float64         float64        float64       float64       float64       float64       float64       float64      float64      float64      float64       float64       float64      float64      float64      float64       float64        float64        float64        float64            float64            float64       float64        float64            float64            float64             float64            float64                 float64        float64         float64         float64         float64         float64         float64         float64         float64        float64              float64               float64               float64              float64            float64               float64            float64             float64               float64           float64             float64            float64              float64            float64                float64                  float64           float64               float64     float64     float64     float64     float64   float64   float64   float64   float64      float64  float64\n",
              "                     ...          ...               ...       ...            ...                ...                     ...                         ...                          ...                    ...                    ...                     ...                    ...                   ...                    ...                     ...                    ...          ...             ...            ...           ...           ...           ...           ...           ...          ...          ...          ...           ...           ...          ...          ...          ...           ...            ...            ...            ...                ...                ...           ...            ...                ...                ...                 ...                ...                     ...            ...             ...             ...             ...             ...             ...             ...             ...            ...                  ...                   ...                   ...                  ...                ...                   ...                ...                 ...                   ...               ...                 ...                ...                  ...                ...                    ...                      ...               ...                   ...         ...         ...         ...         ...       ...       ...       ...       ...          ...      ...\n",
              "Dask Name: describe-numeric, 273 graph layers"
            ],
            "text/html": [
              "<div><strong>Dask DataFrame Structure:</strong></div>\n",
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>SimillarHTTP</th>\n",
              "      <th>Inbound</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>npartitions=1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "<div>Dask Name: describe-numeric, 273 graph layers</div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describes all object columns\n",
        "dask_df.describe(include=['O'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5xOzCY8Zm-mh",
        "outputId": "5fa24648-5ee8-4e9d-f2d2-45d336732e49"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask DataFrame Structure:\n",
              "              Flow ID  Source IP  Destination IP  Timestamp   Label\n",
              "npartitions=1                                                      \n",
              "               object     object          object     object  object\n",
              "                  ...        ...             ...        ...     ...\n",
              "Dask Name: describe, 57 graph layers"
            ],
            "text/html": [
              "<div><strong>Dask DataFrame Structure:</strong></div>\n",
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow ID</th>\n",
              "      <th>Source IP</th>\n",
              "      <th>Destination IP</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>npartitions=1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>object</td>\n",
              "      <td>object</td>\n",
              "      <td>object</td>\n",
              "      <td>object</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "<div>Dask Name: describe, 57 graph layers</div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dask_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw0YUwEesbHS",
        "outputId": "cb14909a-7f52-4695-c3be-772056782e43"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Flow ID', ' Source IP', ' Source Port',\n",
            "       ' Destination IP', ' Destination Port', ' Protocol', ' Timestamp',\n",
            "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
            "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
            "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
            "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
            "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
            "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
            "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
            "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
            "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
            "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
            "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
            "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
            "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
            "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
            "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
            "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
            "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
            "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
            "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
            "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
            "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
            "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
            "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
            "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
            "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
            "       ' Idle Max', ' Idle Min', 'SimillarHTTP', ' Inbound', ' Label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "**To-Do:**\n",
        "*   Drop columns with missing values above a certain threshold, handle remaining missing values.\n",
        "*   Encode categorical columns.\n",
        "*   Normalise dataset.\n",
        "\n",
        "## Dropped Features\n",
        "*   Unnamed: 0: unknown feature.\n",
        "*   Flow Id: constructed from Source Ip, Destination Ip, Source Port, Destination Port and Protocol."
      ],
      "metadata": {
        "id": "2IH9h-H8QULd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into separatate training and testing datasets\n",
        "from dask_ml.model_selection import train_test_split\n",
        "import ipaddress\n",
        "\n",
        "# drops columns\n",
        "to_drop = ['Unnamed: 0', 'Flow ID']\n",
        "dask_df = dask_df.drop(columns = to_drop)\n",
        "\n",
        "# convert ip addresses to integers\n",
        "dask_df['Source IP_int'] = dask_df.apply(lambda x: int (ipaddress.IPv4Address(x[' Source IP'])), meta=('Source IP_int', 'int'), axis=1)\n",
        "dask_df['Destination IP_int'] = dask_df.apply(lambda x: int (ipaddress.IPv4Address(x[' Destination IP'])), meta=('Destination IP_int', 'int'), axis=1)\n",
        "# drop ip addresses\n",
        "dask_df = dask_df.drop(columns = [' Source IP', ' Destination IP'])\n",
        "\n",
        "dask_df[' Timestamp'] = df.to_datetime(dask_df[' Timestamp'], format = '%Y-%m-%d %H:%M:%S.%f', meta = (' Timestamp', 'datetime64[ns]'))\n",
        "\n",
        "# drop duplicate rows\n",
        "dask_df.drop_duplicates()\n",
        "\n",
        "# splits across x and y axis\n",
        "X = dask_df.drop(columns = ' Label')\n",
        "y = dask_df[' Label']\n",
        "\n",
        "# splits 20% of training data into testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "NmI7AY1fQWmp"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = dask_df.columns.values.tolist()\n",
        "types = dask_df.dtypes.tolist()\n",
        "\n",
        "for i in range(0, len(cols)):\n",
        "  print(\"{}: {}\".format(cols[i], types[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw1YVz6OBWwF",
        "outputId": "1412b023-7b16-4d95-eaf3-fcdd98ebea68"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Source Port: int64\n",
            " Destination Port: int64\n",
            " Protocol: int64\n",
            " Timestamp: datetime64[ns]\n",
            " Flow Duration: int64\n",
            " Total Fwd Packets: int64\n",
            " Total Backward Packets: int64\n",
            "Total Length of Fwd Packets: float64\n",
            " Total Length of Bwd Packets: float64\n",
            " Fwd Packet Length Max: float64\n",
            " Fwd Packet Length Min: float64\n",
            " Fwd Packet Length Mean: float64\n",
            " Fwd Packet Length Std: float64\n",
            "Bwd Packet Length Max: float64\n",
            " Bwd Packet Length Min: float64\n",
            " Bwd Packet Length Mean: float64\n",
            " Bwd Packet Length Std: float64\n",
            "Flow Bytes/s: float64\n",
            " Flow Packets/s: float64\n",
            " Flow IAT Mean: float64\n",
            " Flow IAT Std: float64\n",
            " Flow IAT Max: float64\n",
            " Flow IAT Min: float64\n",
            "Fwd IAT Total: float64\n",
            " Fwd IAT Mean: float64\n",
            " Fwd IAT Std: float64\n",
            " Fwd IAT Max: float64\n",
            " Fwd IAT Min: float64\n",
            "Bwd IAT Total: float64\n",
            " Bwd IAT Mean: float64\n",
            " Bwd IAT Std: float64\n",
            " Bwd IAT Max: float64\n",
            " Bwd IAT Min: float64\n",
            "Fwd PSH Flags: int64\n",
            " Bwd PSH Flags: int64\n",
            " Fwd URG Flags: int64\n",
            " Bwd URG Flags: int64\n",
            " Fwd Header Length: int64\n",
            " Bwd Header Length: int64\n",
            "Fwd Packets/s: float64\n",
            " Bwd Packets/s: float64\n",
            " Min Packet Length: float64\n",
            " Max Packet Length: float64\n",
            " Packet Length Mean: float64\n",
            " Packet Length Std: float64\n",
            " Packet Length Variance: float64\n",
            "FIN Flag Count: int64\n",
            " SYN Flag Count: int64\n",
            " RST Flag Count: int64\n",
            " PSH Flag Count: int64\n",
            " ACK Flag Count: int64\n",
            " URG Flag Count: int64\n",
            " CWE Flag Count: int64\n",
            " ECE Flag Count: int64\n",
            " Down/Up Ratio: float64\n",
            " Average Packet Size: float64\n",
            " Avg Fwd Segment Size: float64\n",
            " Avg Bwd Segment Size: float64\n",
            " Fwd Header Length.1: int64\n",
            "Fwd Avg Bytes/Bulk: int64\n",
            " Fwd Avg Packets/Bulk: int64\n",
            " Fwd Avg Bulk Rate: int64\n",
            " Bwd Avg Bytes/Bulk: int64\n",
            " Bwd Avg Packets/Bulk: int64\n",
            "Bwd Avg Bulk Rate: int64\n",
            "Subflow Fwd Packets: int64\n",
            " Subflow Fwd Bytes: int64\n",
            " Subflow Bwd Packets: int64\n",
            " Subflow Bwd Bytes: int64\n",
            "Init_Win_bytes_forward: int64\n",
            " Init_Win_bytes_backward: int64\n",
            " act_data_pkt_fwd: int64\n",
            " min_seg_size_forward: int64\n",
            "Active Mean: float64\n",
            " Active Std: float64\n",
            " Active Max: float64\n",
            " Active Min: float64\n",
            "Idle Mean: float64\n",
            " Idle Std: float64\n",
            " Idle Max: float64\n",
            " Idle Min: float64\n",
            "SimillarHTTP: int64\n",
            " Inbound: int64\n",
            " Label: object\n",
            "Source IP_int: int64\n",
            "Destination IP_int: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "60pYh9NWQbIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build random forest classifier model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rf = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "# grid of parameters to search through when performing cross validation\n",
        "rf_params = {\n",
        "    'class_weight' : ['balanced']\n",
        "}\n",
        "\n",
        "# tests all permutations of the parameters outline in rf_params, returns the best performing model\n",
        "rf_model = GridSearchCV(estimator = rf,\n",
        "                        param_grid = rf_params,\n",
        "                        scoring = [\"accuracy\", \"f1_weighted\", \"roc_auc_ovr\"],\n",
        "                        refit = \"f1_weighted\",\n",
        "                        cv = 5,\n",
        "                        verbose = 3,\n",
        "                        return_train_score = True)\n",
        "\n",
        "# rf_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "9a18V2MuQXB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "O4bSSnwGQfiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NN Setup\n",
        "Import and install required libraries, sets some initial values."
      ],
      "metadata": {
        "id": "236PhyQolLI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import PyTorch and confirm version\n",
        "import torch\n",
        "from torch import nn\n",
        "print(\"Using PyTorch version: {}\".format(torch.__version__))\n",
        "\n",
        "# check the availability of and set the device\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(\"Using {} device.\".format(device))"
      ],
      "metadata": {
        "id": "cHhG7NZ9lahV",
        "outputId": "38791974-5921-4bfe-c610-9621edd0ae19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.2.1+cu121\n",
            "\n",
            "Using cpu device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install Skorch, providing a wrapper for using PyTorch with Sklearn\n",
        "!pip install skorch\n",
        "\n",
        "# import Skorch and confirm version\n",
        "from skorch import __version__ as skorch_version\n",
        "from skorch import NeuralNetClassifier\n",
        "print(\"Using Skorch version: {}\".format(skorch_version))"
      ],
      "metadata": {
        "id": "GUSn5zCTQfGC",
        "outputId": "1dc72297-9640-4f2d-e595-e2a18f565110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Neural Network\n",
        "Currently using a Multilayer Perceptron (MLP), consider swapping to a hybrid model of a MLP and Convolutional Neural Network (CNN) later."
      ],
      "metadata": {
        "id": "AsNxj_cEDydF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN_MLP(nn.Module):\n",
        "  \"\"\"Class that defines a multilayer perceptron model.\"\"\"\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    \"\"\"\n",
        "    Construct a new NN_MLP object.\n",
        "\n",
        "    Parameters:\n",
        "      input_size (int): number of inputs to the input layer.\n",
        "      hidden_size (int): number of inputs to the hidden layer(s).\n",
        "      output_size (int): number of outputs from the output layer, typically 1.\n",
        "    Returns:\n",
        "      : no value returned.\n",
        "    \"\"\"\n",
        "    super(NN_MLP, self).__init__()\n",
        "    # layers\n",
        "    self.h1 = nn.Linear(input_size, hidden_size)\n",
        "    self.h2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.output = nn.Linear(hidden_size, output_size)\n",
        "    # activation functions\n",
        "    self.relu = nn.ReLu()\n",
        "\n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      X (Any): features to make prediction on.\n",
        "    Returns:\n",
        "      Any: predicted value.\n",
        "    \"\"\"\n",
        "    out = self.h1(X)\n",
        "    out = self.relu(out)\n",
        "    out = self.h2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.output(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "OFTGLP7jknbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}